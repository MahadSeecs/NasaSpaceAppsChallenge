{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LGle91W54AKQ",
        "outputId": "e70a9669-dc72-42fc-d1cc-dd03d13d1cfd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dGoxCCqK4Ege",
        "outputId": "3d64675b-c28c-49c6-f532-32d2a1ca6cc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qJMQH_AE3qRP"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import shap\n",
        "    _HAS_SHAP = True\n",
        "except Exception:\n",
        "    _HAS_SHAP = False"
      ],
      "metadata": {
        "id": "AdbbBvxJ4GxO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"cleaned_exoplanets.csv\"      # path to your merged+cleaned csv\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "SAVE_MODEL_PATH = \"exo_lgbm_binary.joblib\""
      ],
      "metadata": {
        "id": "0sWnYVPw4drm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    return df"
      ],
      "metadata": {
        "id": "ofldosfj4Qms"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df):\n",
        "    # keep only CONFIRMED and FALSE POSITIVE rows\n",
        "    df = df[df[\"disposition\"].astype(str).str.upper().isin([\"CONFIRMED\", \"FALSE POSITIVE\"])].copy()\n",
        "\n",
        "    # encode target: 1 = CONFIRMED, 0 = FALSE POSITIVE\n",
        "    y = df[\"disposition\"].astype(str).str.upper().map({\n",
        "        \"FALSE POSITIVE\": 0,\n",
        "        \"CONFIRMED\": 1\n",
        "    }).astype(int)\n",
        "\n",
        "    drop_cols = [\"disposition\", \"src_rowid\", \"unified_id\", \"id_bundle\", \"host_name\"]\n",
        "    feature_cols = [c for c in df.columns if c not in drop_cols]\n",
        "    cat_cols = [\"mission\"]\n",
        "    num_cols = [c for c in feature_cols if c not in cat_cols]\n",
        "    X = df[cat_cols + num_cols].copy()\n",
        "    return X, y, cat_cols, num_cols\n"
      ],
      "metadata": {
        "id": "EnAzYT7-4i63"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_pipeline(cat_cols, num_cols):\n",
        "    pre = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
        "        (\"num\", \"passthrough\", num_cols),\n",
        "    ])\n",
        "\n",
        "    clf = LGBMClassifier(\n",
        "        n_estimators=600,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=-1,\n",
        "        num_leaves=63,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective=\"binary\",\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"prep\", pre),\n",
        "        (\"clf\", clf)\n",
        "    ])\n",
        "    return pipe"
      ],
      "metadata": {
        "id": "f41MYZIn4lFp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "    preds = model.predict(X_test)\n",
        "    print(\"\\n=== Classification Report ===\")\n",
        "    print(classification_report(y_test, preds, target_names=[\"FALSE POSITIVE\", \"CONFIRMED\"], digits=4))\n",
        "    print(\"\\n=== Confusion Matrix ===\")\n",
        "    print(pd.DataFrame(confusion_matrix(y_test, preds),\n",
        "                       index=[\"FALSE POSITIVE\", \"CONFIRMED\"],\n",
        "                       columns=[\"FALSE POSITIVE\", \"CONFIRMED\"]))\n"
      ],
      "metadata": {
        "id": "HlDmizVN4nz2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _feature_names_from_preprocessor(prep):\n",
        "    \"\"\"\n",
        "    Build feature names in the exact order produced by the ColumnTransformer.\n",
        "    Works with OneHotEncoder + passthrough numeric columns.\n",
        "    \"\"\"\n",
        "    names = []\n",
        "    for name, trans, cols in prep.transformers_:\n",
        "        if name == \"remainder\":\n",
        "            # not used here\n",
        "            continue\n",
        "        if trans == \"drop\":\n",
        "            continue\n",
        "        if hasattr(trans, \"get_feature_names_out\"):\n",
        "            # For OneHotEncoder\n",
        "            try:\n",
        "                base = cols\n",
        "                if isinstance(base, (list, tuple, np.ndarray)):\n",
        "                    pass\n",
        "                else:\n",
        "                    base = [base]\n",
        "                names.extend(list(trans.get_feature_names_out(base)))\n",
        "            except Exception:\n",
        "                names.extend(list(trans.get_feature_names_out()))\n",
        "        else:\n",
        "            # passthrough numeric cols\n",
        "            if isinstance(cols, (list, tuple, np.ndarray)):\n",
        "                names.extend(list(cols))\n",
        "            else:\n",
        "                names.append(cols)\n",
        "    return names\n",
        "\n",
        "\n",
        "def explain_permutation(model, X_test, y_test, n_repeats=10, random_state=0):\n",
        "    print(\"\\n=== Permutation Importance ===\")\n",
        "    r = permutation_importance(model, X_test, y_test,\n",
        "                               n_repeats=n_repeats, random_state=random_state)\n",
        "\n",
        "    # Try to get feature names in the exact transformed order\n",
        "    try:\n",
        "        prep = model.named_steps[\"prep\"]\n",
        "        feat_names = _feature_names_from_preprocessor(prep)\n",
        "    except Exception:\n",
        "        # Fallback to whatever ColumnTransformer can provide, or generic names\n",
        "        try:\n",
        "            feat_names = model.named_steps[\"prep\"].get_feature_names_out().tolist()\n",
        "        except Exception:\n",
        "            feat_names = [f\"f{i}\" for i in range(len(r.importances_mean))]\n",
        "\n",
        "    # Hard-align lengths to avoid mismatch crashes\n",
        "    n = len(r.importances_mean)\n",
        "    if len(feat_names) != n:\n",
        "        print(f\"[warn] feature_names({len(feat_names)}) != importances({n}); aligning by truncation.\")\n",
        "        feat_names = feat_names[:n]\n",
        "\n",
        "    imp = pd.DataFrame({\n",
        "        \"feature\": feat_names,\n",
        "        \"mean_importance\": r.importances_mean,\n",
        "        \"std\": r.importances_std\n",
        "    }).sort_values(\"mean_importance\", ascending=False)\n",
        "\n",
        "    print(imp.head(20).to_string(index=False))\n",
        "    return imp\n"
      ],
      "metadata": {
        "id": "tftT_J6M4ptV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    df = load_data(CSV_PATH)\n",
        "    X, y, cat_cols, num_cols = prepare_data(df)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, stratify=y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    model = build_pipeline(cat_cols, num_cols)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    evaluate(model, X_test, y_test)\n",
        "    explain_permutation(model, X_test, y_test)\n",
        "\n",
        "    if SAVE_MODEL_PATH:\n",
        "        import joblib\n",
        "        joblib.dump(model, SAVE_MODEL_PATH)\n",
        "        print(f\"[info] model saved to {SAVE_MODEL_PATH}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qXT2SlCi4wsK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbORTdkQ4yTq",
        "outputId": "17a6c919-ef9f-40ec-b6c1-e4b240688076"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3210, number of negative: 4907\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002958 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2809\n",
            "[LightGBM] [Info] Number of data points in the train set: 8117, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "\n",
            "=== Classification Report ===\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "FALSE POSITIVE     0.9296    0.8826    0.9055      1227\n",
            "     CONFIRMED     0.8335    0.8979    0.8645       803\n",
            "\n",
            "      accuracy                         0.8887      2030\n",
            "     macro avg     0.8816    0.8903    0.8850      2030\n",
            "  weighted avg     0.8916    0.8887    0.8893      2030\n",
            "\n",
            "\n",
            "=== Confusion Matrix ===\n",
            "                FALSE POSITIVE  CONFIRMED\n",
            "FALSE POSITIVE            1083        144\n",
            "CONFIRMED                   82        721\n",
            "\n",
            "=== Permutation Importance ===\n",
            "[warn] feature_names(13) != importances(12); aligning by truncation.\n",
            "       feature  mean_importance      std\n",
            "           ror         0.101576 0.007694\n",
            "  mission_tess         0.089901 0.003070\n",
            "        t0_bjd         0.082118 0.003660\n",
            " insolation_se         0.080345 0.005380\n",
            "         teq_k         0.054581 0.005811\n",
            "     depth_ppm         0.044187 0.005720\n",
            "   st_logg_cgs         0.033842 0.005333\n",
            "duration_hours         0.033498 0.003021\n",
            "     st_teff_k         0.032217 0.004532\n",
            "   period_days         0.021429 0.002334\n",
            "     radius_re         0.008867 0.003777\n",
            "mission_kepler        -0.000296 0.000241\n",
            "[info] model saved to exo_lgbm_binary.joblib\n"
          ]
        }
      ]
    }
  ]
}